{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Eduardo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Eduardo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Eduardo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "# import these modules\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('omw-1.4')\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer() #will remove pre-defined stems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    " \n",
    "# import TfidfTransformer \n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visuals = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(30000,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visuals = df_visuals.sample(30000,random_state=1).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visuals = df_visuals.drop(['index','id','qid1','qid2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How can I stop playing video games?</td>\n",
       "      <td>Should I stop playing video games with my child?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who is better Donald Trump or Hillary Clinton?</td>\n",
       "      <td>Why is Hillary Clinton a better choice than Do...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What do you think is the chance that sometime ...</td>\n",
       "      <td>Do you think there will be another world war/n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why are so many questions posted to Quora that...</td>\n",
       "      <td>Why do people write questions on Quora that co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can there even be a movie ever rated 10/10 on ...</td>\n",
       "      <td>What are your 10/10 movies?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "0                How can I stop playing video games?   \n",
       "1     Who is better Donald Trump or Hillary Clinton?   \n",
       "2  What do you think is the chance that sometime ...   \n",
       "3  Why are so many questions posted to Quora that...   \n",
       "4  Can there even be a movie ever rated 10/10 on ...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0   Should I stop playing video games with my child?             0  \n",
       "1  Why is Hillary Clinton a better choice than Do...             1  \n",
       "2  Do you think there will be another world war/n...             1  \n",
       "3  Why do people write questions on Quora that co...             1  \n",
       "4                        What are your 10/10 movies?             0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_visuals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_value_counts = df_visuals['is_duplicate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    18968\n",
      "1    11032\n",
      "Name: is_duplicate, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(top_5_value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "title = ['Not Duplicate', 'Duplicate']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(title, top_5_value_counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>398782</th>\n",
       "      <td>398782</td>\n",
       "      <td>496695</td>\n",
       "      <td>532029</td>\n",
       "      <td>What is the best marketing automation tool for...</td>\n",
       "      <td>What is the best marketing automation tool for...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "398782  398782  496695  532029   \n",
       "\n",
       "                                                question1  \\\n",
       "398782  What is the best marketing automation tool for...   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "398782  What is the best marketing automation tool for...             1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>398782</td>\n",
       "      <td>496695</td>\n",
       "      <td>532029</td>\n",
       "      <td>What is the best marketing automation tool for...</td>\n",
       "      <td>What is the best marketing automation tool for...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115086</td>\n",
       "      <td>187729</td>\n",
       "      <td>187730</td>\n",
       "      <td>I am poor but I want to invest. What should I do?</td>\n",
       "      <td>I am quite poor and I want to be very rich. Wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>327711</td>\n",
       "      <td>454161</td>\n",
       "      <td>454162</td>\n",
       "      <td>I am from India and live abroad. I met a guy f...</td>\n",
       "      <td>T.I.E.T to Thapar University to Thapar Univers...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>367788</td>\n",
       "      <td>498109</td>\n",
       "      <td>491396</td>\n",
       "      <td>Why do so many people in the U.S. hate the sou...</td>\n",
       "      <td>My boyfriend doesnt feel guilty when he hurts ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151235</td>\n",
       "      <td>237843</td>\n",
       "      <td>50930</td>\n",
       "      <td>Consequences of Bhopal gas tragedy?</td>\n",
       "      <td>What was the reason behind the Bhopal gas trag...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    qid1    qid2                                          question1  \\\n",
       "0  398782  496695  532029  What is the best marketing automation tool for...   \n",
       "1  115086  187729  187730  I am poor but I want to invest. What should I do?   \n",
       "2  327711  454161  454162  I am from India and live abroad. I met a guy f...   \n",
       "3  367788  498109  491396  Why do so many people in the U.S. hate the sou...   \n",
       "4  151235  237843   50930                Consequences of Bhopal gas tragedy?   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the best marketing automation tool for...             1  \n",
       "1  I am quite poor and I want to be very rich. Wh...             0  \n",
       "2  T.I.E.T to Thapar University to Thapar Univers...             0  \n",
       "3  My boyfriend doesnt feel guilty when he hurts ...             0  \n",
       "4  What was the reason behind the Bhopal gas trag...             0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What is the best marketing automation tool for small and mid-size companies?',\n",
       " 'What is the best marketing automation tool for small and mid-sized companies?')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['question1'][0], df['question2'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            30000 non-null  int64 \n",
      " 1   qid1          30000 non-null  int64 \n",
      " 2   qid2          30000 non-null  int64 \n",
      " 3   question1     30000 non-null  object\n",
      " 4   question2     30000 non-null  object\n",
      " 5   is_duplicate  30000 non-null  int64 \n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can remove \"id\" columns\n",
    "\n",
    "df = df.drop(['id','qid1','qid2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove null values\n",
    "\n",
    "df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   question1     30000 non-null  object\n",
      " 1   question2     30000 non-null  object\n",
      " 2   is_duplicate  30000 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 703.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"is_duplicate\" column is the target\n",
    "df_y = df['is_duplicate']\n",
    "df = df.drop('is_duplicate', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the best marketing automation tool for...</td>\n",
       "      <td>What is the best marketing automation tool for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am poor but I want to invest. What should I do?</td>\n",
       "      <td>I am quite poor and I want to be very rich. Wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "0  What is the best marketing automation tool for...   \n",
       "1  I am poor but I want to invest. What should I do?   \n",
       "\n",
       "                                           question2  \n",
       "0  What is the best marketing automation tool for...  \n",
       "1  I am quite poor and I want to be very rich. Wh...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_duplicate\n",
       "0               19013\n",
       "1               10987\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y = pd.DataFrame(df_y)\n",
    "\n",
    "df_y.value_counts()\n",
    "\n",
    "#Can notice an imbalance in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "How could I be fluent in English?                                                                 7\n",
       "How can I lose weight loss?                                                                       6\n",
       "What are the best ways to lose weight fast?                                                       6\n",
       "How can changing 500 and 1000 rupee notes end the black money in India?                           6\n",
       "Why do people often ask questions in Quora while they can Google it themselves?                   6\n",
       "Why do so may people ask questions on Quora that can easily be found by a simple Google searh?    6\n",
       "Name: question1, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['question1'].value_counts().sort_values(ascending=False)[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "How can I lose weight quickly?                                                               8\n",
       "How can someone lose weight quickly?                                                         7\n",
       "What are the safety precautions on handling shotguns proposed by the NRA in Pennsylvania?    7\n",
       "What are the best was to lose weight?                                                        6\n",
       "What are some ways to improve English?                                                       6\n",
       "What are the possible implications of Demonetization of 500 and 1000 rupee notes?            5\n",
       "Name: question2, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['question2'].value_counts().sort_values(ascending=False)[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning\n",
    "\n",
    "- Tokenization\n",
    "- Stopwords cleaning\n",
    "- Removing punctuation\n",
    "- Normalizing\n",
    "- Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopset = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for preprocessing\n",
    "\n",
    "def remove_punct(text):\n",
    "    text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text\n",
    "def remove_stopwords(dataset):    \n",
    "    text = [word for word in dataset.split() if word not in stopset]\n",
    "    return \" \".join(text)\n",
    "def lemma(data):\n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in data]\n",
    "    return lemmatized\n",
    "def stem(dataset):\n",
    "    words = [ps.stem(word) for word in dataset]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "\n",
    "\n",
    "def preprocess(df, column, New_Column):\n",
    "    df[New_Column] = df[column].apply(lambda x: remove_punct(x)) #remove punctuation\n",
    "    df[New_Column] = df[New_Column].apply(lambda x: remove_stopwords(x))\n",
    "    df[New_Column] = df[New_Column].apply(lambda x: word_tokenize(x.lower())) #tokenize and make lowercase\n",
    "    # df[New_Column] = df[New_Column].apply(lambda x: remove_stopwords(x)) #remove stopwords - MUST USE 'New_Column' not original column\n",
    "    df[New_Column] = df[New_Column].apply(lambda x: lemma(x))\n",
    "    df[New_Column] = df[New_Column].apply(lambda x: stem(x))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>question1_post_process</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the best marketing automation tool for...</td>\n",
       "      <td>What is the best marketing automation tool for...</td>\n",
       "      <td>[what, best, market, autom, tool, small, midsi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am poor but I want to invest. What should I do?</td>\n",
       "      <td>I am quite poor and I want to be very rich. Wh...</td>\n",
       "      <td>[i, poor, i, want, invest, what, i]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am from India and live abroad. I met a guy f...</td>\n",
       "      <td>T.I.E.T to Thapar University to Thapar Univers...</td>\n",
       "      <td>[i, india, live, abroad, i, met, guy, franc, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why do so many people in the U.S. hate the sou...</td>\n",
       "      <td>My boyfriend doesnt feel guilty when he hurts ...</td>\n",
       "      <td>[whi, mani, peopl, u, hate, southern, state]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Consequences of Bhopal gas tragedy?</td>\n",
       "      <td>What was the reason behind the Bhopal gas trag...</td>\n",
       "      <td>[consequ, bhopal, ga, tragedi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>What are some good web scraping tutorials?</td>\n",
       "      <td>What are some good web scraping programs?</td>\n",
       "      <td>[what, good, web, scrape, tutori]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>Can I apply for internet banking in SBI withou...</td>\n",
       "      <td>I have internet banking kit of SBI but it's no...</td>\n",
       "      <td>[can, i, appli, internet, bank, sbi, without, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>How much HE laundry detergent do you use in a ...</td>\n",
       "      <td>Can I use regular Dawn dishsoap in my dishwash...</td>\n",
       "      <td>[how, much, he, laundri, deterg, use, top, loa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>What is the best way to understand and learn m...</td>\n",
       "      <td>What are some of the best ways to learn math?</td>\n",
       "      <td>[what, best, way, understand, learn, math]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>What would the Modi-led government do in case ...</td>\n",
       "      <td>If Pakistan mounts a 26/11 type attack again, ...</td>\n",
       "      <td>[what, would, modil, govern, case, anoth, 2611...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question1  \\\n",
       "0      What is the best marketing automation tool for...   \n",
       "1      I am poor but I want to invest. What should I do?   \n",
       "2      I am from India and live abroad. I met a guy f...   \n",
       "3      Why do so many people in the U.S. hate the sou...   \n",
       "4                    Consequences of Bhopal gas tragedy?   \n",
       "...                                                  ...   \n",
       "29995         What are some good web scraping tutorials?   \n",
       "29996  Can I apply for internet banking in SBI withou...   \n",
       "29997  How much HE laundry detergent do you use in a ...   \n",
       "29998  What is the best way to understand and learn m...   \n",
       "29999  What would the Modi-led government do in case ...   \n",
       "\n",
       "                                               question2  \\\n",
       "0      What is the best marketing automation tool for...   \n",
       "1      I am quite poor and I want to be very rich. Wh...   \n",
       "2      T.I.E.T to Thapar University to Thapar Univers...   \n",
       "3      My boyfriend doesnt feel guilty when he hurts ...   \n",
       "4      What was the reason behind the Bhopal gas trag...   \n",
       "...                                                  ...   \n",
       "29995          What are some good web scraping programs?   \n",
       "29996  I have internet banking kit of SBI but it's no...   \n",
       "29997  Can I use regular Dawn dishsoap in my dishwash...   \n",
       "29998      What are some of the best ways to learn math?   \n",
       "29999  If Pakistan mounts a 26/11 type attack again, ...   \n",
       "\n",
       "                                  question1_post_process  \n",
       "0      [what, best, market, autom, tool, small, midsi...  \n",
       "1                    [i, poor, i, want, invest, what, i]  \n",
       "2      [i, india, live, abroad, i, met, guy, franc, p...  \n",
       "3           [whi, mani, peopl, u, hate, southern, state]  \n",
       "4                         [consequ, bhopal, ga, tragedi]  \n",
       "...                                                  ...  \n",
       "29995                  [what, good, web, scrape, tutori]  \n",
       "29996  [can, i, appli, internet, bank, sbi, without, ...  \n",
       "29997  [how, much, he, laundri, deterg, use, top, loa...  \n",
       "29998         [what, best, way, understand, learn, math]  \n",
       "29999  [what, would, modil, govern, case, anoth, 2611...  \n",
       "\n",
       "[30000 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(df, 'question1', 'question1_post_process')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>question1_post_process</th>\n",
       "      <th>question2_post_process</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the best marketing automation tool for...</td>\n",
       "      <td>What is the best marketing automation tool for...</td>\n",
       "      <td>[what, best, market, autom, tool, small, midsi...</td>\n",
       "      <td>[what, best, market, autom, tool, small, midsi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am poor but I want to invest. What should I do?</td>\n",
       "      <td>I am quite poor and I want to be very rich. Wh...</td>\n",
       "      <td>[i, poor, i, want, invest, what, i]</td>\n",
       "      <td>[i, quit, poor, i, want, rich, what, i]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am from India and live abroad. I met a guy f...</td>\n",
       "      <td>T.I.E.T to Thapar University to Thapar Univers...</td>\n",
       "      <td>[i, india, live, abroad, i, met, guy, franc, p...</td>\n",
       "      <td>[tiet, thapar, univers, thapar, univers, insti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why do so many people in the U.S. hate the sou...</td>\n",
       "      <td>My boyfriend doesnt feel guilty when he hurts ...</td>\n",
       "      <td>[whi, mani, peopl, u, hate, southern, state]</td>\n",
       "      <td>[my, boyfriend, doesnt, feel, guilti, hurt, he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Consequences of Bhopal gas tragedy?</td>\n",
       "      <td>What was the reason behind the Bhopal gas trag...</td>\n",
       "      <td>[consequ, bhopal, ga, tragedi]</td>\n",
       "      <td>[what, reason, behind, bhopal, ga, tragedi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>What are some good web scraping tutorials?</td>\n",
       "      <td>What are some good web scraping programs?</td>\n",
       "      <td>[what, good, web, scrape, tutori]</td>\n",
       "      <td>[what, good, web, scrape, program]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>Can I apply for internet banking in SBI withou...</td>\n",
       "      <td>I have internet banking kit of SBI but it's no...</td>\n",
       "      <td>[can, i, appli, internet, bank, sbi, without, ...</td>\n",
       "      <td>[i, internet, bank, kit, sbi, work, whi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>How much HE laundry detergent do you use in a ...</td>\n",
       "      <td>Can I use regular Dawn dishsoap in my dishwash...</td>\n",
       "      <td>[how, much, he, laundri, deterg, use, top, loa...</td>\n",
       "      <td>[can, i, use, regular, dawn, dishsoap, dishwas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>What is the best way to understand and learn m...</td>\n",
       "      <td>What are some of the best ways to learn math?</td>\n",
       "      <td>[what, best, way, understand, learn, math]</td>\n",
       "      <td>[what, best, way, learn, math]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>What would the Modi-led government do in case ...</td>\n",
       "      <td>If Pakistan mounts a 26/11 type attack again, ...</td>\n",
       "      <td>[what, would, modil, govern, case, anoth, 2611...</td>\n",
       "      <td>[if, pakistan, mount, 2611, type, attack, woul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question1  \\\n",
       "0      What is the best marketing automation tool for...   \n",
       "1      I am poor but I want to invest. What should I do?   \n",
       "2      I am from India and live abroad. I met a guy f...   \n",
       "3      Why do so many people in the U.S. hate the sou...   \n",
       "4                    Consequences of Bhopal gas tragedy?   \n",
       "...                                                  ...   \n",
       "29995         What are some good web scraping tutorials?   \n",
       "29996  Can I apply for internet banking in SBI withou...   \n",
       "29997  How much HE laundry detergent do you use in a ...   \n",
       "29998  What is the best way to understand and learn m...   \n",
       "29999  What would the Modi-led government do in case ...   \n",
       "\n",
       "                                               question2  \\\n",
       "0      What is the best marketing automation tool for...   \n",
       "1      I am quite poor and I want to be very rich. Wh...   \n",
       "2      T.I.E.T to Thapar University to Thapar Univers...   \n",
       "3      My boyfriend doesnt feel guilty when he hurts ...   \n",
       "4      What was the reason behind the Bhopal gas trag...   \n",
       "...                                                  ...   \n",
       "29995          What are some good web scraping programs?   \n",
       "29996  I have internet banking kit of SBI but it's no...   \n",
       "29997  Can I use regular Dawn dishsoap in my dishwash...   \n",
       "29998      What are some of the best ways to learn math?   \n",
       "29999  If Pakistan mounts a 26/11 type attack again, ...   \n",
       "\n",
       "                                  question1_post_process  \\\n",
       "0      [what, best, market, autom, tool, small, midsi...   \n",
       "1                    [i, poor, i, want, invest, what, i]   \n",
       "2      [i, india, live, abroad, i, met, guy, franc, p...   \n",
       "3           [whi, mani, peopl, u, hate, southern, state]   \n",
       "4                         [consequ, bhopal, ga, tragedi]   \n",
       "...                                                  ...   \n",
       "29995                  [what, good, web, scrape, tutori]   \n",
       "29996  [can, i, appli, internet, bank, sbi, without, ...   \n",
       "29997  [how, much, he, laundri, deterg, use, top, loa...   \n",
       "29998         [what, best, way, understand, learn, math]   \n",
       "29999  [what, would, modil, govern, case, anoth, 2611...   \n",
       "\n",
       "                                  question2_post_process  \n",
       "0      [what, best, market, autom, tool, small, midsi...  \n",
       "1                [i, quit, poor, i, want, rich, what, i]  \n",
       "2      [tiet, thapar, univers, thapar, univers, insti...  \n",
       "3      [my, boyfriend, doesnt, feel, guilti, hurt, he...  \n",
       "4            [what, reason, behind, bhopal, ga, tragedi]  \n",
       "...                                                  ...  \n",
       "29995                 [what, good, web, scrape, program]  \n",
       "29996           [i, internet, bank, kit, sbi, work, whi]  \n",
       "29997  [can, i, use, regular, dawn, dishsoap, dishwas...  \n",
       "29998                     [what, best, way, learn, math]  \n",
       "29999  [if, pakistan, mount, 2611, type, attack, woul...  \n",
       "\n",
       "[30000 rows x 4 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(df,'question2', 'question2_post_process')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making copy of raw df\n",
    "df_raw = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "- tf-idf\n",
    "- word2vec\n",
    "- word count\n",
    "- number of the same words in both questions\n",
    "- ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# merge texts\n",
    "questions = list(df['question1']) + list(df['question2'])\n",
    "\n",
    "tf = TfidfVectorizer(max_features=3000)\n",
    "q1_arr, q2_arr = np.vsplit(tf.fit_transform(questions).toarray(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 6000)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df1 = pd.DataFrame(q1_arr, index=df.index)\n",
    "temp_df2 = pd.DataFrame(q2_arr, index=df.index)\n",
    "temp_df = pd.concat([temp_df1, temp_df2], axis=1)\n",
    "temp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create character length based features\n",
    "\n",
    "df['len_q1'] = df.question1.apply(lambda x: len(str(x)))\n",
    "\n",
    "df['len_q2'] = df.question2.apply(lambda x: len(str(x)))\n",
    "\n",
    "\n",
    "# difference in lengths of two questions\n",
    "df['diff_len'] = df.len_q1 - df.len_q2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word length based features\n",
    "\n",
    "df['len_word_q1'] = df.question1.apply(lambda x: len(str(x).split()))\n",
    "\n",
    "df['len_word_q2'] = df.question2.apply(lambda x: len(str(x).split()))\n",
    "\n",
    "\n",
    "#difference in lengths by word of two questions\n",
    "df['diff_len_word'] = df.len_word_q1 - df.len_word_q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find common_words\n",
    "\n",
    "df['common_words'] = df.apply(lambda x: len(set(str(x['question1']).lower().split())\n",
    ".intersection(set(str(x['question2']).lower().split()))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "#Word2Vec Question 1\n",
    "\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin.gz\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_ascii(s):\n",
    "    return all(ord(c) < 128 for c in s)\n",
    "\n",
    "\n",
    "\n",
    "def sent2vec(s, model): \n",
    "    M = []\n",
    "    words = str(s).lower().split()\n",
    "    for word in words:\n",
    "        i=is_ascii(word)\n",
    "        if (i):\n",
    "            if word not in stopset:\n",
    "                if word.isalpha():\n",
    "                    if word in model:\n",
    "                        M.append(model[word])\n",
    "    M = np.array(M)\n",
    "    if len(M) > 0:\n",
    "        v = M.sum(axis=0)\n",
    "        return v / np.sqrt((v ** 2).sum())\n",
    "    else:\n",
    "        return np.zeros(300)  #1*300\n",
    "        \n",
    "\n",
    "w2v_q1 = np.array([sent2vec(q, model) for q in df.question1])\n",
    "w2v_q2 = np.array([sent2vec(q, model) for q in df.question2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine, cityblock,jaccard, canberra, euclidean, minkowski, braycurtis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eduardo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\spatial\\distance.py:630: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "c:\\Users\\Eduardo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\spatial\\distance.py:1162: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return l1_diff.sum() / l1_sum.sum()\n"
     ]
    }
   ],
   "source": [
    "df['cosine_distance'] = [cosine(x,y) for (x,y) in zip(w2v_q1, w2v_q2)]  #x y 1-D array\n",
    "df['cityblock_distance'] = [cityblock(x,y) for (x,y) in zip(w2v_q1, w2v_q2)]\n",
    "df['jaccard_distance'] = [jaccard(x,y) for (x,y) in zip(w2v_q1, w2v_q2)]\n",
    "df['canberra_distance'] = [canberra(x,y) for (x,y) in zip(w2v_q1, w2v_q2)]\n",
    "df['euclidean_distance'] = [euclidean(x,y) for (x,y) in zip(w2v_q1, w2v_q2)]\n",
    "df['minkowski_distance'] = [minkowski(x,y,3) for (x,y) in zip(w2v_q1, w2v_q2)]\n",
    "df['braycurtis_distance'] = [braycurtis(x,y) for (x,y) in zip(w2v_q1, w2v_q2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>question1_post_process</th>\n",
       "      <th>question2_post_process</th>\n",
       "      <th>len_q1</th>\n",
       "      <th>len_q2</th>\n",
       "      <th>diff_len</th>\n",
       "      <th>len_word_q1</th>\n",
       "      <th>len_word_q2</th>\n",
       "      <th>diff_len_word</th>\n",
       "      <th>common_words</th>\n",
       "      <th>cosine_distance</th>\n",
       "      <th>cityblock_distance</th>\n",
       "      <th>jaccard_distance</th>\n",
       "      <th>canberra_distance</th>\n",
       "      <th>euclidean_distance</th>\n",
       "      <th>minkowski_distance</th>\n",
       "      <th>braycurtis_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the best marketing automation tool for...</td>\n",
       "      <td>What is the best marketing automation tool for...</td>\n",
       "      <td>[what, best, market, autom, tool, small, midsi...</td>\n",
       "      <td>[what, best, market, autom, tool, small, midsi...</td>\n",
       "      <td>76</td>\n",
       "      <td>77</td>\n",
       "      <td>-1</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am poor but I want to invest. What should I do?</td>\n",
       "      <td>I am quite poor and I want to be very rich. Wh...</td>\n",
       "      <td>[i, poor, i, want, invest, what, i]</td>\n",
       "      <td>[i, quit, poor, i, want, rich, what, i]</td>\n",
       "      <td>49</td>\n",
       "      <td>57</td>\n",
       "      <td>-8</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>-3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.107566</td>\n",
       "      <td>6.404117</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.455885</td>\n",
       "      <td>0.463823</td>\n",
       "      <td>0.20996</td>\n",
       "      <td>0.231503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "0  What is the best marketing automation tool for...   \n",
       "1  I am poor but I want to invest. What should I do?   \n",
       "\n",
       "                                           question2  \\\n",
       "0  What is the best marketing automation tool for...   \n",
       "1  I am quite poor and I want to be very rich. Wh...   \n",
       "\n",
       "                              question1_post_process  \\\n",
       "0  [what, best, market, autom, tool, small, midsi...   \n",
       "1                [i, poor, i, want, invest, what, i]   \n",
       "\n",
       "                              question2_post_process  len_q1  len_q2  \\\n",
       "0  [what, best, market, autom, tool, small, midsi...      76      77   \n",
       "1            [i, quit, poor, i, want, rich, what, i]      49      57   \n",
       "\n",
       "   diff_len  len_word_q1  len_word_q2  diff_len_word  common_words  \\\n",
       "0        -1           12           12              0            11   \n",
       "1        -8           12           15             -3             7   \n",
       "\n",
       "   cosine_distance  cityblock_distance  jaccard_distance  canberra_distance  \\\n",
       "0         0.000000            0.000000               0.0           0.000000   \n",
       "1         0.107566            6.404117               1.0         101.455885   \n",
       "\n",
       "   euclidean_distance  minkowski_distance  braycurtis_distance  \n",
       "0            0.000000             0.00000             0.000000  \n",
       "1            0.463823             0.20996             0.231503  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['question1', 'question2', 'question1_post_process',\n",
       "       'question2_post_process', 'len_q1', 'len_q2', 'diff_len', 'len_word_q1',\n",
       "       'len_word_q2', 'diff_len_word', 'common_words', 'cosine_distance',\n",
       "       'cityblock_distance', 'jaccard_distance', 'canberra_distance',\n",
       "       'euclidean_distance', 'minkowski_distance', 'braycurtis_distance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Advanced Features\n",
    "\n",
    "combined_df = pd.concat([df, temp_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 6018)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    29805.000000\n",
       "mean         0.425145\n",
       "std          0.240180\n",
       "min          0.000000\n",
       "25%          0.282068\n",
       "50%          0.409923\n",
       "75%          0.561032\n",
       "max          1.131726\n",
       "Name: braycurtis_distance, dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['braycurtis_distance'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['braycurtis_distance'] = df['braycurtis_distance'].fillna(df['braycurtis_distance'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced_df = combined_df.drop(['question1','question2','question1_post_process','question2_post_process'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function take a dataframe\n",
    "# as a parameter and returning list\n",
    "# of column names whose contents \n",
    "# are duplicates.\n",
    "def getDuplicateColumns(df):\n",
    "  \n",
    "    # Create an empty set\n",
    "    duplicateColumnNames = set()\n",
    "      \n",
    "    # Iterate through all the columns \n",
    "    # of dataframe\n",
    "    for x in range(df.shape[1]):\n",
    "          \n",
    "        # Take column at xth index.\n",
    "        col = df.iloc[:, x]\n",
    "          \n",
    "        # Iterate through all the columns in\n",
    "        # DataFrame from (x + 1)th index to\n",
    "        # last index\n",
    "        for y in range(x + 1, df.shape[1]):\n",
    "              \n",
    "            # Take column at yth index.\n",
    "            otherCol = df.iloc[:, y]\n",
    "              \n",
    "            # Check if two columns at x & y\n",
    "            # index are equal or not,\n",
    "            # if equal then adding \n",
    "            # to the set\n",
    "            if col.equals(otherCol):\n",
    "                duplicateColumnNames.add(df.columns.values[y])\n",
    "                  \n",
    "    # Return list of unique column names \n",
    "    # whose contents are duplicates.\n",
    "    return list(duplicateColumnNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get list of duplicate columns - WARNING: took 49 minutes to complete\n",
    "\n",
    "# duplicateColNames = getDuplicateColumns(advanced_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in duplicateColNames:\n",
    "#     print('Column Name : ', column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced_df = advanced_df.drop([1504, 138, 1869], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#More advanced NLP - Future progress\n",
    "\n",
    "# from transformers import XLNetTokenizer, XLNetModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class XLNET_Embedding():\n",
    "\n",
    "#     def __init__(self, name, clean):\n",
    "#         self.name = name\n",
    "#         self.clean = clean\n",
    "#         self.tokenizer = XLNetTokenizer.from_pretrained(self.name)\n",
    "#         self.model = XLNetModel.from_pretrained(self.name)\n",
    "\n",
    "#     def vectors(self, s):\n",
    "#         input_ids = torch.tensor(self.tokenizer.encode(s,\n",
    "#                                  add_special_tokens=True)).unsqueeze(0)\n",
    "#         outputs = self.model(input_ids)\n",
    "#         last_hidden_states = outputs[0][:, -1].detach().numpy()\n",
    "#         return last_hidden_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "\n",
    "Different modeling techniques can be used:\n",
    "\n",
    "- logistic regression\n",
    "- XGBoost\n",
    "- LSTMs\n",
    "- etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Basic Features\n",
    "\n",
    "Basic_features = ['len_q1', 'len_q2', 'diff_len', 'len_word_q1',\n",
    "       'len_word_q2', 'diff_len_word', 'common_words', 'cosine_distance',\n",
    "       'cityblock_distance', 'jaccard_distance', 'canberra_distance',\n",
    "       'euclidean_distance', 'minkowski_distance', 'braycurtis_distance']\n",
    "       \n",
    "length_features = ['len_q1', 'len_q2', 'diff_len', 'len_word_q1', 'len_word_q2', 'diff_len_word', 'common_words']\n",
    "       \n",
    "Word2Vec_features = ['cosine_distance', 'cityblock_distance', 'jaccard_distance', 'canberra_distance', 'euclidean_distance', 'minkowski_distance', 'braycurtis_distance']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_basic, X_test_basic, y_train_basic, y_test_basic = train_test_split(df[Basic_features], df_y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_length, X_test_length, y_train_length, y_test_length = train_test_split(df[length_features], df_y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_word, X_test_word, y_train_word, y_test_word = train_test_split(df[Word2Vec_features], df_y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_gb = XGBClassifier(\n",
    "    max_depth=80,\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    colsample_bytree=.7,\n",
    "    gamma=0,\n",
    "    reg_alpha=4,\n",
    "    objective='binary:logistic',\n",
    "    eta=0.3,\n",
    "    silent=1,\n",
    "    )\n",
    "\n",
    "\n",
    "logres = LogisticRegression(C=0.1, solver='sag', max_iter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:19:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7133333333333334"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Basic Features XGBoost\n",
    "\n",
    "X_gb.fit(X_train_basic,y_train_basic)\n",
    "y_predxgb = X_gb.predict(X_test_basic)\n",
    "accuracy_score(y_test_basic,y_predxgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:20:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6970666666666666"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#length Features XGBoost\n",
    "\n",
    "X_gb.fit(X_train_length, y_train_length)\n",
    "y_predxgb = X_gb.predict(X_test_length)\n",
    "accuracy_score(y_test_length,y_predxgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:20:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6545333333333333"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Word Features XGBoost\n",
    "\n",
    "X_gb.fit(X_train_word, y_train_word)\n",
    "y_predxgb = X_gb.predict(X_test_word)\n",
    "accuracy_score(y_test_word,y_predxgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eduardo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6697333333333333"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Basic Features Logistic Regression\n",
    "\n",
    "logres.fit(X_train_basic,y_train_basic)\n",
    "y_predlog = logres.predict(X_test_basic)\n",
    "accuracy_score(y_test_basic, y_predlog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eduardo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6622666666666667"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#length Features Logistic Regression\n",
    "\n",
    "logres.fit(X_train_length,y_train_length)\n",
    "y_predlog = logres.predict(X_test_length)\n",
    "accuracy_score(y_test_length, y_predlog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eduardo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6637333333333333"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Word2vec Features Logistic Regression\n",
    "\n",
    "logres.fit(X_train_word,y_train_word)\n",
    "y_predlog = logres.predict(X_test_word)\n",
    "accuracy_score(y_test_word, y_predlog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "91e32b75ecf3080d170411cb1649c483b59a4efe3288a5b0a9b6b201a0b09750"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
